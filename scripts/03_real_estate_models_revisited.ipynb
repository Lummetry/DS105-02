{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c9f0291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pytorch 2.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch as th\n",
    "print(\"Using pytorch {}\".format(th.__version__))\n",
    "\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import set_pretty_prints, load_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a34047",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_pretty_prints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3226dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset('imobiliare.ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c9c906",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace888bb-46a5-46cc-97ba-fd7f70cec279",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sqmp = df[\"Price/Surface\"]\n",
    "y_price = df['Price']\n",
    "\n",
    "# TODO: select viable features\n",
    "START = 1\n",
    "END = 9\n",
    "X = df.iloc[:,START:END]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e075d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b9f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e967ae",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba33c821",
   "metadata": {},
   "outputs": [],
   "source": [
    "field = 'nr cam'\n",
    "x_label = 'Nr rooms'\n",
    "title = 'Distribution of nr of rooms per apartment'\n",
    "X[field].hist(bins=20)\n",
    "plt.xlabel(x_label)\n",
    "plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b90dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyse a few more features\n",
    "field = 'mp'\n",
    "x_label = 'Square meters per property'\n",
    "title = 'Distribution of sqm per property'\n",
    "X[field].hist(bins=20)\n",
    "plt.xlabel(x_label)\n",
    "plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0395cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyse target distribution\n",
    "target = y_price\n",
    "title = 'Distribution of price'\n",
    "x_label = 'Price'\n",
    "plt.hist(target, bins=50)\n",
    "plt.title(title)\n",
    "plt.xlabel(x_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afa122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Re-display the target distribution\n",
    "target = y_price\n",
    "title = \"Distribution of price in log scale\"\n",
    "x_label = \"Price\"\n",
    "plot_param = 'log'\n",
    "plot_param_value = True\n",
    "kwargs = {plot_param : plot_param_value}\n",
    "plt.hist(target, bins=50, **kwargs)\n",
    "plt.title(title)\n",
    "plt.xlabel(x_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce209002",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c643f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corr_features = ['nr cam', 'mp', 'parter', 'et1-2', 'et3+','etaj max', 'typ_decom', 'bloc nou', 'Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83153d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[new_corr_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b913474",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77104c52",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "- further process X data maybe\n",
    "- construct normal eq and determine model coefs `(((XtX)^-1)Xt)y (y = x*w => w = y/x)`\n",
    "- validate results (how, when)\n",
    "\n",
    "`f(X) = y = X[0]*w[0] + X[1]*w[1] + .... X[N-1]*w[N-1] +X[N]*w[N] | X[N] == 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c164ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d544883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e899d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7811fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.max()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff21113",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92788300",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_X[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1affd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4324d142-6729-4591-a4e3-c80c74b8ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_X_n = (np_X - np_X.mean(0)) / np_X.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c7087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_X_n[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313a4cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_y = y_price.values\n",
    "np_y[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e045e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_y_n = (np_y - np_y.min()) / (np_y.max() - np_y.min())\n",
    "np_y_n[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be241ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_y.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af98e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa676245",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_norm_sub = np_y.min()\n",
    "y_norm_div = np_y.max() - np_y.min()\n",
    "y_test = np_y_n * y_norm_div + y_norm_sub\n",
    "y_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e3b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write normal eq for raw data\n",
    "np_weights = np.linalg.pinv(np_X.T.dot(np_X)).dot(np_X.T).dot(np_y)\n",
    "\n",
    "# TODO: write normal eq for normalized data\n",
    "np_weights_n = np.linalg.pinv(np_X_n.T.dot(np_X_n)).dot(np_X_n.T).dot(np_y_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17612e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92a8344",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_weights_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4485a963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: calc predictions for raw data model\n",
    "np_y_preds = np_X.dot(np_weights)\n",
    "\n",
    "#TODO: calc predictions for normalized data model\n",
    "np_y_preds_n = np_X_n.dot(np_weights_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4795c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_y_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa77cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(np_y_preds)\n",
    "plt.title('Raw model predictions')\n",
    "plt.figure()\n",
    "plt.hist(np_y_preds_n)\n",
    "plt.title('Normed data model predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6aa458",
   "metadata": {},
   "source": [
    "### One more model before testing results\n",
    "\n",
    "Lets further improve model by adding bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a1d320",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones(shape=(np_X_n.shape[0], 1))\n",
    "ones[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b49206",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_X_nb = np.concatenate((np_X_n, ones), axis=-1)\n",
    "np_X_nb[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643c832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate weights\n",
    "np_weights_nb = np.linalg.inv(np_X_nb.T.dot(np_X_nb) + 0.02 * np.eye(np_X_nb.shape[1])).dot(np_X_nb.T).dot(np_y_n)\n",
    "np_weights_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299903cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate predictions\n",
    "np_y_preds_nb = np_X_nb.dot(np_weights_nb)\n",
    "np_y_preds_nb[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5681aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np_y_preds_nb, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6091bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_y_pred_price = np_y_preds\n",
    "np_y_pred_n_price = np_y_preds_n * y_norm_div + y_norm_sub\n",
    "np_y_pred_nb_price = np_y_preds_nb  * y_norm_div + y_norm_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc606b6",
   "metadata": {},
   "source": [
    "### Now lets prepare some friendly calitative analysis outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e48092",
   "metadata": {},
   "source": [
    "Raw model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e48e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_raw = pd.DataFrame(\n",
    "    {\n",
    "        'GOLD' : y_price,\n",
    "        'PRED' : np_y_pred_price.round(0),\n",
    "    }\n",
    ")\n",
    "df_result_raw.head(10)\n",
    "df_result_raw.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da397496",
   "metadata": {},
   "source": [
    "Normed data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2626c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_n = pd.DataFrame(\n",
    "    {\n",
    "        'GOLD' : y_price,\n",
    "        'PRED' : np_y_pred_n_price.round(0),\n",
    "    }\n",
    ")\n",
    "df_result_n.head(10)\n",
    "df_result_n.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6bb0dd",
   "metadata": {},
   "source": [
    "Normed & bias added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce27b9fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_result_nb = pd.DataFrame(\n",
    "    {\n",
    "        'GOLD' : y_price,\n",
    "        'PRED' : np_y_pred_nb_price.round(0),\n",
    "    }\n",
    ")\n",
    "df_result_nb.head(10)\n",
    "df_result_nb.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fedbe4f",
   "metadata": {},
   "source": [
    "Now lets see some quantitative analysis of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0d15ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete code below\n",
    "abs_err = np.abs(y_price - np_y_pred_nb_price)\n",
    "abs_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b640f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_err = abs_err / y_price\n",
    "proc_err = proc_err * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc83f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(\n",
    "    {\n",
    "        'GOLD' : y_price,\n",
    "        'PRED' : np_y_pred_nb_price.round(0),\n",
    "        'ERR%' : proc_err.round(2)\n",
    "    }\n",
    ")\n",
    "df_result.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c346ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6052f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_err.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e26bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neq(inputs, gold):\n",
    "    # TODO:\n",
    "    weights = np.linalg.pinv(inputs.T.dot(inputs)).dot(inputs.T).dot(gold)\n",
    "    return weights\n",
    "\n",
    "def evaluate(theta, inputs, gold, y_div, y_sub, name=\"\"):\n",
    "    _y_pred = inputs.dot(theta)\n",
    "    _y_vals = _y_pred * y_div + y_sub\n",
    "    \n",
    "    _y_true = gold * y_div + y_sub\n",
    "    \n",
    "    res_err = np.abs(_y_true - _y_vals)\n",
    "    prc_err = res_err / _y_true *100\n",
    "    \n",
    "    overall = prc_err.mean()\n",
    "    df_result = pd.DataFrame(\n",
    "        {\n",
    "        'GOLD' : _y_true,\n",
    "        'PRED' : _y_vals.round(0),\n",
    "        'ERR%' : prc_err.round(2)\n",
    "        }\n",
    "    )\n",
    "    print('Results for', name)\n",
    "    print(df_result.head(20))\n",
    "    print(df_result.tail(20))\n",
    "    print(\"Overall error: {:.1f}%\".format(overall))\n",
    "    return overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d516ddf-e52a-42cb-ba73-0b98ed37eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that Web Page format includes the area name.\n",
    "df['Location'] = df['WebPage'].apply(lambda getloc : getloc.split('/')[5])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.Location.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_locs= pd.get_dummies(df.Location, prefix='loc', columns=['Location'], dtype=float)\n",
    "np_locs = df_locs.values\n",
    "\n",
    "np_X_loc_n = np.concatenate((np_X_n, np_locs), axis=1)\n",
    "np_X_loc_nb = np.concatenate((np_X_loc_n, ones), axis=1)\n",
    "df_locs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_X_loc_nb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('No location data:\\n{}'.format(np_X_nb[:5]))\n",
    "print('\\With location data:\\n{}'.format(np_X_loc_nb[:5, :20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets see some correlations !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_locs['Price'] = df.Price\n",
    "df_locs.corr().iloc[-10:,-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can train the model with location data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b63735-9d72-46bf-a0ec-2f277494d05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_weights_loc_nb = train_neq(np_X_loc_nb, np_y_n)\n",
    "np_weights_loc_nb[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e8e607-2fb8-4a19-a71b-c4ce4a62ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    theta=np_weights_loc_nb,\n",
    "    inputs=np_X_loc_nb,\n",
    "    gold=np_y_n,\n",
    "    y_div=y_norm_div,\n",
    "    y_sub=y_norm_sub,\n",
    "    name='TRAIN',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653c5612-1d41-49bf-bef0-88f4bbafc3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The previous normalize-data with bias model error was: {:.2f}%\".format(proc_err.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252498aa",
   "metadata": {},
   "source": [
    "# Now for a more correct and real-life approach\n",
    "We will not use the pre-processed data and perform a train-test split. There is no need for train-dev-test split as we do not have a training process to use the dev on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1727da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np_x_loc_trn, np_x_loc_tst, np_y_trn, np_y_tst = train_test_split(np_X_loc_nb, np_y_n, test_size=0.2)\n",
    "# but is this enough ... ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets do the custom split \"dance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_idx(data_size, test_size):\n",
    "  test_len = int(data_size * test_size)\n",
    "  all_idx = np.arange(data_size)\n",
    "  np.random.shuffle(all_idx)\n",
    "  test_idx = all_idx[:test_len]\n",
    "  train_idx = all_idx[test_len:]\n",
    "  return train_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = train_test_split_idx(np_X_loc_nb.shape[0], test_size=0.2)\n",
    "print(train_idx.shape, test_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_experiments =[\n",
    "  {\n",
    "    \"train\" : np_X[train_idx],\n",
    "    \"test\" : np_X[test_idx],\n",
    "    \"name\" : \"Normal\"\n",
    "  },\n",
    "  {\n",
    "    \"train\" : np_X_n[train_idx],\n",
    "    \"test\" : np_X_n[test_idx],\n",
    "    \"name\" : \"Normalized\",\n",
    "  },\n",
    "  {\n",
    "    \"train\" : np_X_nb[train_idx],\n",
    "    \"test\" : np_X_nb[test_idx],\n",
    "    \"name\" : \"Normalized + Bias\",\n",
    "  },\n",
    "  {\n",
    "    \"train\" : np_X_loc_nb[train_idx],\n",
    "    \"test\" : np_X_loc_nb[test_idx],\n",
    "    \"name\" : \"Normalized + Bias + Location\",\n",
    "  }\n",
    "]\n",
    "\n",
    "dct_results = {\n",
    "  'Experiment' : [],\n",
    "  'Train Score' : [],\n",
    "  'Test Score' : []\n",
    "}\n",
    "\n",
    "for dct_experiment in lst_experiments:\n",
    "  experiment_name = dct_experiment[\"name\"]\n",
    "  print(\"Running experiment {}\".format(experiment_name), flush=True)\n",
    "  np_x_train = dct_experiment[\"train\"]\n",
    "  np_x_test = dct_experiment[\"test\"]\n",
    "  np_y_train = np_y_n[train_idx]\n",
    "  np_y_test = np_y_n[test_idx]\n",
    "  np_theta = train_neq(np_x_train, np_y_train)\n",
    "  train_score = evaluate(\n",
    "      theta=np_theta,\n",
    "      inputs=np_x_train,\n",
    "      gold=np_y_train,\n",
    "      y_div=y_norm_div,\n",
    "      y_sub=y_norm_sub,\n",
    "      name='TRAIN {}'.format(dct_experiment[\"name\"]),\n",
    "  )\n",
    "  test_score = evaluate(\n",
    "      theta=np_theta,\n",
    "      inputs=np_x_test,\n",
    "      gold=np_y_test,\n",
    "      y_div=y_norm_div,\n",
    "      y_sub=y_norm_sub,\n",
    "      name='TEST {}'.format(dct_experiment[\"name\"]),\n",
    "  )\n",
    "  dct_results[\"Train Score\"].append(train_score)\n",
    "  dct_results[\"Test Score\"].append(test_score)\n",
    "  dct_results[\"Experiment\"].append(experiment_name)\n",
    "\n",
    "df_result = pd.DataFrame(dct_results).sort_values(by=\"Test Score\")\n",
    "print(df_result)\n",
    "\n",
    "# now lets serialize the results\n",
    "df_result.to_csv('outputs/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c30094a",
   "metadata": {},
   "source": [
    "# Simple Neural model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396b8450-5853-474d-b8c1-8726a11bea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "\n",
    "# A*B*C*D*E*F*G*H*I*J*K*L*M*N*O*P*Q*R*S*T*U*V*W*X*Y*Z === A*X \n",
    "\n",
    "class SimpleLinerRealEstateModel(th.nn.Module):\n",
    "    # Parameters:\n",
    "    # n_feats - number of input features\n",
    "    # n_hid1 - number of output features in the first hidden layers\n",
    "    def __init__(self, n_feats, n_hid1=32):\n",
    "        super().__init__()\n",
    "        self.n_feats = n_feats\n",
    "        self.hidden1 = th.nn.Linear(n_feats, n_hid1)\n",
    "        self.act1 = th.nn.ReLU()\n",
    "        self.readout = th.nn.Linear(n_hid1, 1)\n",
    "        return\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        #############################\n",
    "        # TODO: complete forward pass \n",
    "        #############################\n",
    "        th_x = inputs\n",
    "        th_x = self.hidden1(th_x)\n",
    "        th_x = self.act1(th_x)\n",
    "        th_out = self.readout(th_x)\n",
    "        return th_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5123f123-7b67-4ccd-bf76-d87b329b8413",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleLinerRealEstateModel(198, 256)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529403ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(np.unique(np_X_loc_nb[:,-1])) ==  1\n",
    "np.unique(np_X_loc_nb[:,-1])\n",
    "np_x_train = np_X_loc_nb[train_idx, :-1]\n",
    "np_x_test_full = np_X_loc_nb[test_idx, :-1]\n",
    "print(np_x_train.shape, np_x_test_full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08818e3",
   "metadata": {},
   "source": [
    "### Introducing \"dev\" dataset\n",
    "Now we will have a training process so we need a dev dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0569152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_PRC = 0.5\n",
    "DEV_SIZE = int(np_x_test_full.shape[0] * DEV_PRC)\n",
    "np_x_dev = np_x_test_full[:DEV_SIZE,:]\n",
    "np_x_test = np_x_test_full[DEV_SIZE:,:]\n",
    "print(np_x_dev.shape, np_x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6f8257",
   "metadata": {},
   "source": [
    "Now we tensorize but we eliminate the bias term "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b56ff50-b731-477e-8e7e-34354aaab91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_x_trn = th.tensor(np_x_train, dtype=th.float32)\n",
    "th_x_dev = th.tensor(np_x_dev, dtype=th.float32)\n",
    "th_x_test = th.tensor(np_x_test, dtype=th.float32)\n",
    "print(th_x_trn.shape, th_x_dev.shape, th_x_test.shape)\n",
    "th_x_trn[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca33f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da28e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_x_train_slice_gpu = th_x_trn[:10].to(th.device('cuda'))\n",
    "th_x_train_slice_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_y_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c709742",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_y_trn = np_y_n[train_idx]\n",
    "np_y_tst = np_y_n[test_idx]\n",
    "# split in dev-test\n",
    "np_y_dev = np_y_tst[:DEV_SIZE].reshape(-1,1)\n",
    "np_y_test = np_y_tst[DEV_SIZE:].reshape(-1,1)\n",
    "\n",
    "np_y_trn = np_y_trn.reshape(-1,1)\n",
    "np_y_trn[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf46cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# TODO: complete y tensors creation \n",
    "#############################\n",
    "th_y_trn = th.tensor(np_y_trn, dtype=th.float32)\n",
    "th_y_dev = th.tensor(np_y_dev, dtype=th.float32)\n",
    "th_y_test = th.tensor(np_y_test, dtype=th.float32)\n",
    "th_y_trn[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b819aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(th_y_dev.shape)\n",
    "print(th_x_dev.shape)\n",
    "print(th_y_test.shape)\n",
    "print(th_x_test.shape)\n",
    "print(th_y_trn.shape)\n",
    "print(th_x_trn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77b4331",
   "metadata": {},
   "source": [
    "### Model training data feed\n",
    "Now lets prepare the internal mechanics for data feeding in the model training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c69ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "th_ds = th.utils.data.TensorDataset(th_x_trn, th_y_trn)\n",
    "th_dl = th.utils.data.DataLoader(th_ds, batch_size=BATCH_SIZE)\n",
    "th_x_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4403fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for th_x_batch, th_y_batch in th_dl:\n",
    "    break\n",
    "print(th_x_batch.shape, th_y_batch.shape)\n",
    "th_x_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07608473",
   "metadata": {},
   "source": [
    "Re-writing evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839bc749",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def th_evaluate(m, th_inputs, gold, y_div, y_sub, name=\"\", verbose=False):\n",
    "  m.eval()\n",
    "  with th.no_grad():\n",
    "    #############################\n",
    "    # TODO: complete yhat generation \n",
    "    #############################            \n",
    "    _y_pred = m(th_inputs)\n",
    "      \n",
    "  _y_vals = _y_pred * y_div + y_sub\n",
    "  \n",
    "  _y_true = gold * y_div + y_sub\n",
    "  \n",
    "  res_err = th.abs(_y_true - _y_vals)\n",
    "  prc_err = res_err / _y_true * 100\n",
    "  \n",
    "  overall = prc_err.mean()\n",
    "  if verbose:\n",
    "      df_result = pd.DataFrame(\n",
    "          {\n",
    "          'GOLD' : _y_true.cpu().numpy().ravel(),\n",
    "          'PRED' : _y_vals.cpu().numpy().ravel().round(0),\n",
    "          'ERR%' : prc_err.cpu().numpy().ravel().round(2)\n",
    "          }\n",
    "      )\n",
    "      print('Results for', name)\n",
    "      print(df_result.head(20))\n",
    "      print(df_result.tail(20))    \n",
    "  m.train()\n",
    "  return overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f196fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = th.nn.MSELoss()\n",
    "# optimizer: weights = weights - alpha * grads # alpha << 1\n",
    "opt = th.optim.Adam(model.parameters(), lr=5e-5)\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d83dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "TOTAL_NR_EPOCHS = 100\n",
    "# re-init model\n",
    "model = SimpleLinerRealEstateModel(th_x_trn.shape[1], 256)\n",
    "print(model)\n",
    "opt = th.optim.Adam(model.parameters(), lr=1e-4)\n",
    "best_dev_err = 10_000\n",
    "wait_time = 0\n",
    "max_nr_of_succesive_fails = 5\n",
    "for epoch in range(TOTAL_NR_EPOCHS):\n",
    "  if DEBUG and epoch >0:\n",
    "      break\n",
    "  for th_x_batch, th_y_batch in th_dl:\n",
    "    # compute current inferred values with forward prop\n",
    "    th_y_hat = model(th_x_batch)\n",
    "    # compute loss (compare results with actual truth)\n",
    "    th_loss = loss_func(input=th_y_hat, target=th_y_batch) #((th_y_hat - th_y_batch)**2).mean()\n",
    "    # nullfy the gradients\n",
    "    opt.zero_grad()\n",
    "    # compute loss 1st derv wrt all model weights (grads)\n",
    "    th_loss.backward()\n",
    "    \n",
    "    if DEBUG:\n",
    "        th_param = next(model.parameters())\n",
    "        print(th_param.grad)\n",
    "        break\n",
    "    \n",
    "    # apply gradients to weights with a hopefully smart approach\n",
    "    opt.step()\n",
    "  #end current epoch\n",
    "  if not DEBUG:\n",
    "    # now we evaluate on TRAIN and DEV to see how good we are\n",
    "    train_err = th_evaluate(\n",
    "        m=model,\n",
    "        th_inputs=th_x_trn,\n",
    "        gold=th_y_trn,\n",
    "        y_div=y_norm_div,\n",
    "        y_sub=y_norm_sub,\n",
    "        verbose=False,\n",
    "        name='TRAIN @ Epoch {}'.format(epoch)\n",
    "    )\n",
    "    dev_err = th_evaluate(\n",
    "        m=model,\n",
    "        th_inputs=th_x_dev,\n",
    "        gold=th_y_dev,\n",
    "        y_div=y_norm_div,\n",
    "        y_sub=y_norm_sub,\n",
    "        verbose=False,\n",
    "        name='DEV @ Epoch {}'.format(epoch)\n",
    "    )\n",
    "    if best_dev_err > dev_err:\n",
    "        best_dev_err = dev_err\n",
    "        wait_time = 0\n",
    "        print(\"BEST MODEL @ Epoch {} - train err: {:.2f}%, dev err: {:.2f}% \".format(epoch, train_err, dev_err), flush=True)\n",
    "    else:\n",
    "        wait_time += 1\n",
    "        if wait_time > max_nr_of_succesive_fails:\n",
    "            print(f\"Stopped training at epoch {epoch} !\")\n",
    "            break\n",
    "\n",
    "if not DEBUG: \n",
    "  # finally we evaluate on TEST\n",
    "  th_evaluate(\n",
    "    m=model,\n",
    "    th_inputs=th_x_test,\n",
    "    gold=th_y_test,\n",
    "    y_div=y_norm_div,\n",
    "    y_sub=y_norm_sub,\n",
    "    verbose=True,\n",
    "    name='Final TEST'\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800184a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = th.arange(0, num_locations, 1).view(1,-1).repeat(th_x_trn.shape[0], 1)[:10, :17]\n",
    "t2 = th_x_trn[:10, 100:117]\n",
    "print(t1.shape, t2.shape)\n",
    "print(t1)\n",
    "print(t2)\n",
    "(t1 * t2).sum(-1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36267350-0751-4816-ac9e-fdaf3372d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute data with locations IDs in order to move to location embeddings.\n",
    "num_locations = df['Location'].nunique()\n",
    "\n",
    "# Turn one hot location encoding into index encoding\n",
    "def th_add_location_idx(th_x):\n",
    "  # Use a mask of consecutive numbers in the one dimension\n",
    "  mask = th.arange(0, num_locations, 1).view(1,-1).repeat(th_x.shape[0], 1)\n",
    "  # Multiply with the one hot encoding to mask values not equal to our index\n",
    "  mask = mask * th_x[:,8:]\n",
    "  # Do a row sum to get the actual index.\n",
    "  locs = th.sum(mask, 1).view(-1, 1)\n",
    "  return th.cat((th_x[:,:8], locs), axis=1)\n",
    "\n",
    "th_x_dev_embed = th_add_location_idx(th_x_dev)\n",
    "th_x_trn_embed = th_add_location_idx(th_x_trn)\n",
    "th_x_test_embed = th_add_location_idx(th_x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c29c6e-660e-47e7-9856-a750339c6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_x_dev_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c083d9-1494-42ba-99b4-d484cb5cdc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_x_test_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e45a38-6ce7-45cf-be7f-5a64cfda884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_x_trn_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e692b5ff-c990-4e77-a87c-02205b29c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_x_dev_embed[:20, -3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_ds = th.utils.data.TensorDataset(th_x_trn_embed, th_y_trn)\n",
    "th_dl = th.utils.data.DataLoader(th_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "for th_x_batch, th_y_batch in th_dl:\n",
    "  break\n",
    "print(th_x_batch.shape, th_y_batch.shape)\n",
    "th_x_batch[:, -4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LOCATIONS = num_locations\n",
    "N_INPUTS = 8 + 1 # 8 features + 1 location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoreAdvancedRealEstate(th.nn.Module):\n",
    "  def __init__(self, embed_size=5, hsize=32, num_locations=NUM_LOCATIONS):\n",
    "    super().__init__()\n",
    "    self.embed_size = embed_size\n",
    "    self.embed = th.nn.Embedding(num_embeddings=num_locations, embedding_dim=embed_size)\n",
    "    self.hidden1 = th.nn.Linear((N_INPUTS -1 + embed_size), hsize)\n",
    "    self.act1 = th.nn.ReLU()\n",
    "    self.readout = th.nn.Linear(hsize, 1)\n",
    "    return\n",
    "  \n",
    "  def forward(self, inputs):\n",
    "    th_x_feat_input = inputs[:, :-1]\n",
    "    th_x_embd_input = inputs[:, -1].long()\n",
    "    th_embeds = self.embed(th_x_embd_input)\n",
    "    th_x = th.cat((th_x_feat_input, th_embeds), axis=-1)\n",
    "    th_x = self.hidden1(th_x)\n",
    "    th_x = self.act1(th_x)\n",
    "    th_out = self.readout(th_x)\n",
    "    return th_out\n",
    "  \n",
    "  def get_embeds(self, inputs):\n",
    "    th_x_embd_input = inputs[:, -1].long()\n",
    "    th_embeds = self.embed(th_x_embd_input)\n",
    "    return th_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = MoreAdvancedRealEstate(embed_size=5, hsize=32)\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_x_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.get_embeds(th_x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initial model:\\n{}\\nModel Error: {}\".format(model, dev_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = NUM_LOCATIONS ** (1/3)\n",
    "embed_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  del model\n",
    "except:\n",
    "  pass\n",
    "DEBUG = False\n",
    "TOTAL_NR_EPOCHS = 100\n",
    "# re-init model\n",
    "model2 = MoreAdvancedRealEstate(embed_size=5, hsize=256)\n",
    "print(model2)\n",
    "opt = th.optim.Adam(model2.parameters(), lr=1e-4)\n",
    "best_dev_err = 10_000\n",
    "wait_time = 0\n",
    "max_nr_of_succesive_fails = 5\n",
    "for epoch in range(TOTAL_NR_EPOCHS):\n",
    "  if DEBUG and epoch >0:\n",
    "      break\n",
    "  for th_x_batch, th_y_batch in th_dl:\n",
    "    # compute current inferred values with forward prop\n",
    "    th_y_hat = model2(th_x_batch)\n",
    "    # compute loss (compare results with actual truth)\n",
    "    th_loss = loss_func(input=th_y_hat, target=th_y_batch) #((th_y_hat - th_y_batch)**2).mean()\n",
    "    # nullfy the gradients\n",
    "    opt.zero_grad()\n",
    "    # compute loss 1st derv wrt all model weights (grads)\n",
    "    th_loss.backward()\n",
    "    \n",
    "    if DEBUG:\n",
    "        th_param = next(model2.parameters())\n",
    "        print(th_param.grad)\n",
    "        break\n",
    "    \n",
    "    # apply gradients to weights with a hopefully smart approach\n",
    "    opt.step()\n",
    "  #end current epoch\n",
    "  if not DEBUG:\n",
    "    # now we evaluate on TRAIN and DEV to see how good we are\n",
    "    train_err = th_evaluate(\n",
    "        m=model2,\n",
    "        th_inputs=th_x_trn_embed,\n",
    "        gold=th_y_trn,\n",
    "        y_div=y_norm_div,\n",
    "        y_sub=y_norm_sub,\n",
    "        verbose=False,\n",
    "        name='TRAIN @ Epoch {}'.format(epoch)\n",
    "    )\n",
    "    dev_err = th_evaluate(\n",
    "        m=model2,\n",
    "        th_inputs=th_x_dev_embed,\n",
    "        gold=th_y_dev,\n",
    "        y_div=y_norm_div,\n",
    "        y_sub=y_norm_sub,\n",
    "        verbose=False,\n",
    "        name='DEV @ Epoch {}'.format(epoch)\n",
    "    )\n",
    "    if best_dev_err > dev_err:\n",
    "        best_dev_err = dev_err\n",
    "        wait_time = 0\n",
    "        print(\"BEST MODEL2 @ Epoch {} - train err: {:.2f}%, dev err: {:.2f}% \".format(epoch, train_err, dev_err), flush=True)\n",
    "    else:\n",
    "        wait_time += 1\n",
    "        if wait_time > max_nr_of_succesive_fails:\n",
    "            print(f\"Stopped training at epoch {epoch} !\")\n",
    "            break\n",
    "\n",
    "if not DEBUG: \n",
    "  # finally we evaluate on TEST\n",
    "  th_evaluate(\n",
    "    m=model2,\n",
    "    th_inputs=th_x_test_embed,\n",
    "    gold=th_y_test,\n",
    "    y_div=y_norm_div,\n",
    "    y_sub=y_norm_sub,\n",
    "    verbose=True,\n",
    "    name='Final TEST'\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  th_evaluate(\n",
    "    m=model2,\n",
    "    th_inputs=th_x_test_embed,\n",
    "    gold=th_y_test,\n",
    "    y_div=y_norm_div,\n",
    "    y_sub=y_norm_sub,\n",
    "    verbose=True,\n",
    "    name='Final TEST'\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
