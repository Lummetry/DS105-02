{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9f0291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import set_pretty_prints, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a34047",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_pretty_prints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3226dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset('imobiliare.ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c9c906",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe683b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sqmp = df[\"Price/Surface\"]\n",
    "y_price = df['Price']\n",
    "\n",
    "# TODO: select viable features\n",
    "START = 1\n",
    "END = 9\n",
    "X = df.iloc[:,START:END]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e075d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b9f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e967ae",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba33c821",
   "metadata": {},
   "outputs": [],
   "source": [
    "field = 'nr cam'\n",
    "x_label = 'Nr rooms'\n",
    "title = 'Distribution of nr of rooms per apartment'\n",
    "X[field].hist(bins=20)\n",
    "plt.xlabel(x_label)\n",
    "plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b90dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyse a few more features\n",
    "field = 'mp'\n",
    "x_label = 'Square meters per property'\n",
    "title = 'Distribution of sqm per property'\n",
    "X[field].hist(bins=20)\n",
    "plt.xlabel(x_label)\n",
    "plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0395cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyse target distribution\n",
    "target = y_price\n",
    "title = 'Distribution of price'\n",
    "x_label = 'Price'\n",
    "plt.hist(target, bins=50)\n",
    "plt.title(title)\n",
    "plt.xlabel(x_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afa122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Re-display the target distribution\n",
    "target = y_price\n",
    "title = \"Distribution of price in log scale\"\n",
    "x_label = \"Price\"\n",
    "plot_param = 'log'\n",
    "plot_param_value = True\n",
    "kwargs = {plot_param : plot_param_value}\n",
    "plt.hist(target, bins=50, **kwargs)\n",
    "plt.title(title)\n",
    "plt.xlabel(x_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce209002",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c643f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corr_features = ['nr cam', 'mp', 'parter', 'et1-2', 'et3+','etaj max', 'typ_decom', 'bloc nou', 'Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83153d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[new_corr_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b913474",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77104c52",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "- further process X data maybe\n",
    "- construct normal eq and determine model coefs `(((XtX)^-1)Xt)y (y = x*w => w = y/x)`\n",
    "- validate results (how, when)\n",
    "\n",
    "`f(X) = y = X[0]*w[0] + X[1]*w[1] + .... X[N]*w[N] +X[N+1]*w[N+1] | X[N+1] == 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c164ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d544883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e899d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7811fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff21113",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92788300",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np_X[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1affd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b01063",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_X_n = (np_X - np_X.mean(0)) / np_X.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c7087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_X_n[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313a4cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_y = y_price.values\n",
    "np_y[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e045e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np_y_n = (np_y - np_y.min()) / (np_y.max() - np_y.min())\n",
    "np_y_n[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be241ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_y.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af98e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa676245",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_norm_sub = np_y.min()\n",
    "y_norm_div = np_y.max() - np_y.min()\n",
    "y_test = np_y_n * y_norm_div + y_norm_sub\n",
    "y_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e3b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write normal eq for raw data\n",
    "np_weights = np.linalg.pinv(np_X.T.dot(np_X)).dot(np_X.T).dot(np_y)\n",
    "\n",
    "# TODO: write normal eq for normalized data\n",
    "np_weights_n = np.linalg.pinv(np_X_n.T.dot(np_X_n)).dot(np_X_n.T).dot(np_y_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17612e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92a8344",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_weights_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4485a963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: calc predictions for raw data model\n",
    "np_y_preds = np_X.dot(np_weights)\n",
    "\n",
    "#TODO: calc predictions for normalized data model\n",
    "np_y_preds_n = np_X_n.dot(np_weights_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4795c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_y_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa77cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(np_y_preds)\n",
    "plt.title('Raw model predictions')\n",
    "plt.figure()\n",
    "plt.hist(np_y_preds_n)\n",
    "plt.title('Normed data model predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6aa458",
   "metadata": {},
   "source": [
    "### One more model before testing results\n",
    "\n",
    "Lets further improve model by adding bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a1d320",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ones = np.ones(shape=(np_X_n.shape[0], 1))\n",
    "ones[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b49206",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_X_nb = np.concatenate((np_X_n, ones), axis=-1)\n",
    "np_X_nb[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643c832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate weights\n",
    "np_weights_nb = np.linalg.inv(np_X_nb.T.dot(np_X_nb) + 0.02 * np.eye(np_X_nb.shape[1])).dot(np_X_nb.T).dot(np_y_n)\n",
    "np_weights_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299903cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate predictions\n",
    "np_y_preds_nb = np_X_nb.dot(np_weights_nb)\n",
    "np_y_preds_nb[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5681aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np_y_preds_nb, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6091bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_y_pred_price = np_y_preds\n",
    "np_y_pred_n_price = np_y_preds_n * y_norm_div + y_norm_sub\n",
    "np_y_pred_nb_price = np_y_preds_nb  * y_norm_div + y_norm_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc606b6",
   "metadata": {},
   "source": [
    "### Now lets prepare some friendly calitative analysis outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e48092",
   "metadata": {},
   "source": [
    "Raw model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e48e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_raw = pd.DataFrame(\n",
    "    {\n",
    "        'GOLD' : y_price,\n",
    "        'PRED' : np_y_pred_price.round(0),\n",
    "    }\n",
    ")\n",
    "df_result_raw.head(10)\n",
    "df_result_raw.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da397496",
   "metadata": {},
   "source": [
    "Normed data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2626c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_n = pd.DataFrame(\n",
    "    {\n",
    "        'GOLD' : y_price,\n",
    "        'PRED' : np_y_pred_n_price.round(0),\n",
    "    }\n",
    ")\n",
    "df_result_n.head(10)\n",
    "df_result_n.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6bb0dd",
   "metadata": {},
   "source": [
    "Normed & bias added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce27b9fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_result_nb = pd.DataFrame(\n",
    "    {\n",
    "        'GOLD' : y_price,\n",
    "        'PRED' : np_y_pred_nb_price.round(0),\n",
    "    }\n",
    ")\n",
    "df_result_nb.head(10)\n",
    "df_result_nb.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fedbe4f",
   "metadata": {},
   "source": [
    "Now lets see some quantitative analysis of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0d15ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete code below\n",
    "abs_err = np.abs(y_price - np_y_pred_nb_price)\n",
    "abs_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b640f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_err = abs_err / y_price\n",
    "proc_err = proc_err * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc83f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(\n",
    "    {\n",
    "        'GOLD' : y_price,\n",
    "        'PRED' : np_y_pred_nb_price.round(0),\n",
    "        'ERR%' : proc_err.round(2)\n",
    "    }\n",
    ")\n",
    "df_result.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c346ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6052f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_err.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e26bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neq(inputs, gold):\n",
    "    # TODO:\n",
    "    weights = np.linalg.pinv(inputs.T.dot(inputs)).dot(inputs.T).dot(gold)\n",
    "    return weights\n",
    "\n",
    "def evaluate(theta, inputs, gold, y_div, y_sub, name=\"\"):\n",
    "    _y_pred = inputs.dot(theta)\n",
    "    _y_vals = _y_pred * y_div + y_sub\n",
    "    \n",
    "    _y_true = gold * y_div + y_sub\n",
    "    \n",
    "    res_err = np.abs(_y_true - _y_vals)\n",
    "    prc_err = res_err / _y_true *100\n",
    "    \n",
    "    overall = prc_err.mean()\n",
    "    df_result = pd.DataFrame(\n",
    "        {\n",
    "        'GOLD' : _y_true,\n",
    "        'PRED' : _y_vals.round(0),\n",
    "        'ERR%' : prc_err.round(2)\n",
    "        }\n",
    "    )\n",
    "    print('Results for', name)\n",
    "    print(df_result.head(20))\n",
    "    print(df_result.tail(20))\n",
    "    print(\"Overall error: {:.1f}%\".format(overall))\n",
    "    return overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252498aa",
   "metadata": {},
   "source": [
    "# Now for a more correct and real-life approach\n",
    "We will not use the pre-processed data and perform a train-test split. There is no need for train-dev-test split as we do not have a training process to use the dev on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1727da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_trn, x_tst, y_trn, y_tst = train_test_split(np_X_nb, np_y_n, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a6eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = train_neq(\n",
    "    inputs=x_trn,\n",
    "    gold=y_trn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873573d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc0f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    theta=theta,\n",
    "    inputs=x_trn,\n",
    "    gold=y_trn,\n",
    "    y_div=y_norm_div,\n",
    "    y_sub=y_norm_sub,\n",
    "    name='TRAIN',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23949b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\n",
    "    theta=theta,\n",
    "    inputs=x_tst,\n",
    "    gold=y_tst,\n",
    "    y_div=y_norm_div,\n",
    "    y_sub=y_norm_sub,\n",
    "    name='TEST',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c30094a",
   "metadata": {},
   "source": [
    "# Simple Neural model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0b3146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "\n",
    "class SimpleLinerRealEstateModel(th.nn.Module):\n",
    "    def __init__(self, n_feats, n_hid1=32):\n",
    "        super().__init__()\n",
    "        self.hidden1 = th.nn.Linear(n_feats, n_hid1)\n",
    "        self.act1 = th.nn.ReLU()\n",
    "        self.readout = th.nn.Linear(n_hid1, 1)\n",
    "        return\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        #############################\n",
    "        # TODO: complete forward pass \n",
    "        #############################\n",
    "        th_x = self.hidden1(inputs)\n",
    "        th_x = self.act1(th_x)\n",
    "        th_out = self.readout(th_x)\n",
    "        return th_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f04db1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleLinerRealEstateModel(8, 256)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529403ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b89a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tst.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08818e3",
   "metadata": {},
   "source": [
    "### Introducing \"dev\" dataset\n",
    "Now we will have a training process so we need a dev dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0569152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_PRC = 0.5\n",
    "DEV_SIZE = int(x_tst.shape[0] * DEV_PRC)\n",
    "x_dev = x_tst[:DEV_SIZE,:]\n",
    "x_test = x_tst[DEV_SIZE:,:]\n",
    "x_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6f8257",
   "metadata": {},
   "source": [
    "Now we tensorize but we eliminate the bias term "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd8d430",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "th_x_trn = th.tensor(x_trn[:,:-1], dtype=th.float32)\n",
    "th_x_dev = th.tensor(x_dev[:,:-1], dtype=th.float32)\n",
    "th_x_test = th.tensor(x_test[:,:-1], dtype=th.float32)\n",
    "th_x_trn[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca33f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da28e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_x_train_slice_gpu = th_x_trn[:10].to(th.device('cuda'))\n",
    "th_x_train_slice_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c709742",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev = y_tst[:DEV_SIZE].reshape(-1,1)\n",
    "y_test = y_tst[DEV_SIZE:].reshape(-1,1)\n",
    "y_trn = y_trn.reshape(-1,1)\n",
    "y_trn[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf46cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# TODO: complete y tensors creation \n",
    "#############################\n",
    "th_y_trn = th.tensor(y_trn, dtype=th.float32)\n",
    "th_y_dev = th.tensor(y_dev, dtype=th.float32)\n",
    "th_y_test = th.tensor(y_test, dtype=th.float32)\n",
    "th_y_trn[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b819aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(th_y_dev.shape)\n",
    "print(th_x_dev.shape)\n",
    "print(th_y_test.shape)\n",
    "print(th_x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77b4331",
   "metadata": {},
   "source": [
    "### Model training data feed\n",
    "Now lets prepare the internal mechanics for data feeding in the model training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c69ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "th_ds = th.utils.data.TensorDataset(th_x_trn, th_y_trn)\n",
    "th_dl = th.utils.data.DataLoader(th_ds, batch_size=BATCH_SIZE)\n",
    "th_x_trn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4403fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for th_x_batch, th_y_batch in th_dl:\n",
    "    break\n",
    "th_x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acae2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_x_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b42bc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49e87b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "th.abs(th.tensor([-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07608473",
   "metadata": {},
   "source": [
    "Re-writing evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839bc749",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def th_evaluate(m, th_inputs, gold, y_div, y_sub, name=\"\", verbose=False):\n",
    "    m.eval()\n",
    "    with th.no_grad():\n",
    "        #############################\n",
    "        # TODO: complete yhat generation \n",
    "        #############################            \n",
    "        _y_pred = m(th_inputs)\n",
    "        \n",
    "    _y_vals = _y_pred * y_div + y_sub\n",
    "    \n",
    "    _y_true = gold * y_div + y_sub\n",
    "    \n",
    "    res_err = th.abs(_y_true - _y_vals)\n",
    "    prc_err = res_err / _y_true * 100\n",
    "    \n",
    "    overall = prc_err.mean()\n",
    "    if verbose:\n",
    "        df_result = pd.DataFrame(\n",
    "            {\n",
    "            'GOLD' : _y_true.cpu().numpy().ravel(),\n",
    "            'PRED' : _y_vals.cpu().numpy().ravel().round(0),\n",
    "            'ERR%' : prc_err.cpu().numpy().ravel().round(2)\n",
    "            }\n",
    "        )\n",
    "        print('Results for', name)\n",
    "        print(df_result.head(20))\n",
    "        print(df_result.tail(20))    \n",
    "    m.train()\n",
    "    return overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f196fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = th.nn.MSELoss()\n",
    "# optimizer: weights = weights - alpha * grads # alpha << 1\n",
    "opt = th.optim.Adam(model.parameters(), lr=5e-5)\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d83dac7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "TOTAL_NR_EPOCHS = 100\n",
    "# re-init model\n",
    "model = SimpleLinerRealEstateModel(8, 256)\n",
    "opt = th.optim.Adam(model.parameters(), lr=1e-4)\n",
    "best_dev_err = 10_000\n",
    "wait_time = 0\n",
    "max_nr_of_succesive_fails = 5\n",
    "for epoch in range(TOTAL_NR_EPOCHS):\n",
    "    if DEBUG and epoch >0:\n",
    "        break\n",
    "    for th_x_batch, th_y_batch in th_dl:\n",
    "        # compute current inferred values with forward prop\n",
    "        th_y_hat = model(th_x_batch)\n",
    "        # compute loss (compare results with actual truth)\n",
    "        th_loss = loss_func(input=th_y_hat, target=th_y_batch) #((th_y_hat - th_y_batch)**2).mean()\n",
    "        # nullfy the gradients\n",
    "        opt.zero_grad()\n",
    "        # compute loss 1st derv wrt all model weights (grads)\n",
    "        th_loss.backward()\n",
    "        \n",
    "        if DEBUG:\n",
    "            th_param = next(model.parameters())\n",
    "            print(th_param.grad)\n",
    "            break\n",
    "        \n",
    "        # apply gradients to weights with a hopefully smart approach\n",
    "        opt.step()\n",
    "    if not DEBUG:\n",
    "        # now we evaluate on TRAIN and DEV to see how good we are\n",
    "        th_evaluate(\n",
    "            m=model,\n",
    "            th_inputs=th_x_trn,\n",
    "            gold=th_y_trn,\n",
    "            y_div=y_norm_div,\n",
    "            y_sub=y_norm_sub,\n",
    "            verbose=False,\n",
    "            name='TRAIN @ Epoch {}'.format(epoch)\n",
    "        )\n",
    "        dev_err = th_evaluate(\n",
    "            m=model,\n",
    "            th_inputs=th_x_dev,\n",
    "            gold=th_y_dev,\n",
    "            y_div=y_norm_div,\n",
    "            y_sub=y_norm_sub,\n",
    "            verbose=False,\n",
    "            name='DEV @ Epoch {}'.format(epoch)\n",
    "        )\n",
    "        if best_dev_err > dev_err:\n",
    "            best_dev_err = dev_err\n",
    "            wait_time = 0\n",
    "            print(\"BEST MODEL @ Epoch {}\".format(epoch))\n",
    "        else:\n",
    "            wait_time += 1\n",
    "            if wait_time > max_nr_of_succesive_fails:\n",
    "                print(\"STOP TRAINING !\")\n",
    "                break\n",
    "\n",
    "if not DEBUG: \n",
    "    # finally we evaluate on TEST\n",
    "    th_evaluate(\n",
    "        m=model,\n",
    "        th_inputs=th_x_test,\n",
    "        gold=th_y_test,\n",
    "        y_div=y_norm_div,\n",
    "        y_sub=y_norm_sub,\n",
    "        verbose=True,\n",
    "        name='Final TEST'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800184a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addfbade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "\n",
    "class BetterLinerRealEstateModel(th.nn.Module):\n",
    "    def __init__(self, n_input_feats, layers=[32], activation=th.nn.ReLU):\n",
    "        super().__init__()\n",
    "        self.layers = th.nn.ModuleList()\n",
    "        n_prev = n_input_feats\n",
    "        for layer_size in layers:\n",
    "            hid = th.nn.Linear(n_prev, layer_size)\n",
    "            act = activation()\n",
    "            self.layers.append(hid)\n",
    "            self.layers.append(act)\n",
    "            n_prev = layer_size\n",
    "        \n",
    "        self.readout = th.nn.Linear(n_prev, 1)\n",
    "        return\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        th_x = inputs\n",
    "        for layer in self.layers:\n",
    "            th_x = layer(th_x)\n",
    "        th_out = self.readout(th_x)\n",
    "        return th_out\n",
    "\n",
    "test_model = BetterLinerRealEstateModel(8, [64, 32, 16], activation=th.nn.Sigmoid)\n",
    "test_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8600f1f",
   "metadata": {},
   "source": [
    "### Even closer to production grade experiments: model factories\n",
    "Now we prepare a basic model factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1976c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_and_optimizer(layers, activation, opt_class, lr):\n",
    "    model = BetterLinerRealEstateModel(8, layers, activation)\n",
    "    opt = opt_class(model.parameters(), lr=lr)\n",
    "    return model, opt\n",
    "\n",
    "#############################\n",
    "# TODO: create a example model\n",
    "#############################   \n",
    "test_model, test_opt = get_model_and_optimizer(layers=[32, 4], activation=th.nn.ReLU, opt_class=th.optim.SGD, lr=0.01)\n",
    "test_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657e9b2d",
   "metadata": {},
   "source": [
    "### Grid search\n",
    "Next step is grid searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d4b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# TODO: complete missing grid search params\n",
    "############################# \n",
    "\n",
    "dct_grid_space = {\n",
    "    'layers' : [\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "    ],\n",
    "    'activation' : [\n",
    "        None,\n",
    "        None,\n",
    "    ],\n",
    "    'opt_class' : [\n",
    "        th.optim.SGD,\n",
    "        th.optim.Adam\n",
    "    ],\n",
    "    'lr' : [\n",
    "        0.001,\n",
    "        0.01,\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38126709",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = th.nn.MSELoss()\n",
    "dct_grid_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef07d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, opt, max_epochs=TOTAL_NR_EPOCHS):\n",
    "    best_dev_err = 100\n",
    "    wait_time = 0\n",
    "    max_nr_of_succesive_fails = 2\n",
    "    for epoch in range(max_epochs):\n",
    "        for th_x_batch, th_y_batch in th_dl:\n",
    "            # TODO: compute current inferred values with forward prop\n",
    "            th_y_hat = None\n",
    "            # compute loss (compare results with actual truth)\n",
    "            th_loss = None #((th_y_hat - th_y_batch)**2).mean()\n",
    "            # TODO: nullfy the gradients\n",
    "            None\n",
    "            # TODO: compute loss 1st derv wrt all model weights (grads)\n",
    "            None\n",
    "            # TODO: apply gradients to weights with a hopefully smart approach\n",
    "            None\n",
    "            \n",
    "        # now we evaluate on TRAIN and DEV to see how good we are\n",
    "        dev_err = th_evaluate(\n",
    "            m=model,\n",
    "            th_inputs=th_x_dev,\n",
    "            gold=y_dev,\n",
    "            y_div=y_norm_div,\n",
    "            y_sub=y_norm_sub,\n",
    "            verbose=False,\n",
    "            name='DEV @ Epoch {}'.format(epoch)\n",
    "        )\n",
    "        if best_dev_err > dev_err:\n",
    "            best_dev_err = dev_err\n",
    "            wait_time = 0\n",
    "            print(\"\\rBEST MODEL @ Epoch {}\\r\".format(epoch), end='', flush=True)\n",
    "        else:\n",
    "            wait_time += 1\n",
    "            if wait_time > max_nr_of_succesive_fails:\n",
    "                print(\"\\nSTOP TRAINING !\")\n",
    "                break\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5049057",
   "metadata": {},
   "source": [
    "### Grid pre-processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95599a4",
   "metadata": {},
   "source": [
    "Prepare grid in a friendly format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c808d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = []\n",
    "grid_values = []\n",
    "for k in dct_grid_space:\n",
    "    grid_params.append(k)\n",
    "    grid_values.append(dct_grid_space[k])\n",
    "import itertools\n",
    "grid_combs = list(itertools.product(*grid_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4487300",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8fe528",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9313c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grid_combs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280a9565",
   "metadata": {},
   "source": [
    "Lets see how a actual iteration looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41855ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for grid_iter in range(len(grid_combs)):\n",
    "    dct_curr_params = {k:v for k,v in zip(grid_params, grid_combs[grid_iter])}\n",
    "    break\n",
    "dct_curr_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e6a70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model_and_optimizer(**dct_curr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898ef39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8ac430",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118a76d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_res = {\n",
    "    'MODEL' : [],\n",
    "    'DEV' : [],\n",
    "    'TEST' : [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd43fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare grid search\n",
    "grid_params = []\n",
    "grid_values = []\n",
    "for k in dct_grid_space:\n",
    "    grid_params.append(k)\n",
    "    grid_values.append(dct_grid_space[k])\n",
    "import itertools\n",
    "grid_combs = list(itertools.product(*grid_values))\n",
    "\n",
    "# run grid search\n",
    "for grid_iter in range(len(grid_combs)):\n",
    "    dct_curr_params = {k:v for k,v in zip(grid_params, grid_combs[grid_iter])}\n",
    "    print(\"Running grid search space model #{}/{}\".format(grid_iter+1,len(grid_combs)))\n",
    "    # TODO: use model factory to get model and optimizer\n",
    "    model, opt = None\n",
    "    model = train_model(model, opt)\n",
    "    models.append(model)\n",
    "    dev_err = th_evaluate(\n",
    "        m=model,\n",
    "        th_inputs=th_x_dev,\n",
    "        gold=y_dev,\n",
    "        y_div=y_norm_div,\n",
    "        y_sub=y_norm_sub,\n",
    "        verbose=False,\n",
    "        name='Final DEV'\n",
    "    )\n",
    "    test_err = th_evaluate(\n",
    "        m=model,\n",
    "        th_inputs=th_x_test,\n",
    "        gold=y_test,\n",
    "        y_div=y_norm_div,\n",
    "        y_sub=y_norm_sub,\n",
    "        verbose=False,\n",
    "        name='Final TEST'\n",
    "    )\n",
    "    dct_res['MODEL'].append('Model #' + str(grid_iter + 1))\n",
    "    dct_res['DEV'].append(dev_err)\n",
    "    dct_res['TEST'].append(test_err)\n",
    "    for k,v in dct_curr_params.items():\n",
    "        if k not in dct_res:\n",
    "            dct_res[k] = []\n",
    "        if not isinstance(v, (list, int, float)):\n",
    "            dct_res[k].append(v.__name__)\n",
    "        else:\n",
    "            dct_res[k].append(v)\n",
    "    print('Result so far:\\n{}'.format(pd.DataFrame(dct_res).sort_values('TEST')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265ea340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: RUN GRID SEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c319163",
   "metadata": {},
   "source": [
    "#### Finally we can now narrow the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73950978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
